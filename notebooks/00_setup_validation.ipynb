{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Setup Validation\n",
    "\n",
    "This notebook validates the project setup including:\n",
    "- Python environment and dependencies\n",
    "- GCP authentication and connectivity\n",
    "- Data files presence\n",
    "- Configuration validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Python Environment Check\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xgboost\n",
    "\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"xgboost: {xgboost.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: GCP Libraries Check\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import google.auth\n",
    "\n",
    "print(f\"google-cloud-aiplatform: {aiplatform.__version__}\")\n",
    "\n",
    "# Check authentication\n",
    "credentials, project = google.auth.default()\n",
    "print(f\"\\n✓ Authenticated\")\n",
    "print(f\"  Project: {project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load and Validate Config\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "with open(\"../configs/config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  GCP Project: {config['gcp']['project_id']}\")\n",
    "print(f\"  Region: {config['gcp']['region']}\")\n",
    "print(f\"  Bucket: {config['gcp']['bucket']}\")\n",
    "print(f\"  Experiment: {config['vertex_ai']['experiment_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Verify GCS Bucket Access\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client(project=config[\"gcp\"][\"project_id\"])\n",
    "bucket_name = config[\"gcp\"][\"bucket\"]\n",
    "\n",
    "try:\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    print(f\"✓ Bucket '{bucket_name}' accessible\")\n",
    "    print(f\"  Location: {bucket.location}\")\n",
    "    print(f\"  Storage class: {bucket.storage_class}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Bucket error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Verify Vertex AI Connection\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(\n",
    "    project=config[\"gcp\"][\"project_id\"],\n",
    "    location=config[\"gcp\"][\"region\"],\n",
    ")\n",
    "\n",
    "print(f\"✓ Vertex AI initialized\")\n",
    "print(f\"  Project: {config['gcp']['project_id']}\")\n",
    "print(f\"  Location: {config['gcp']['region']}\")\n",
    "\n",
    "# List existing experiments (if any)\n",
    "experiments = aiplatform.Experiment.list()\n",
    "print(f\"  Existing experiments: {len(experiments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Create Experiment (if not exists)\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "experiment_name = config[\"vertex_ai\"][\"experiment_name\"]\n",
    "\n",
    "try:\n",
    "    experiment = aiplatform.Experiment.create(\n",
    "        experiment_name=experiment_name,\n",
    "        description=\"Olist Customer Intelligence Platform - ML Experiments\"\n",
    "    )\n",
    "    print(f\"✓ Created experiment: {experiment_name}\")\n",
    "except Exception as e:\n",
    "    # Experiment might already exist\n",
    "    experiment = aiplatform.Experiment(experiment_name=experiment_name)\n",
    "    print(f\"✓ Using existing experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Verify Data Files\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/raw\")\n",
    "expected_files = [\n",
    "    \"olist_orders_dataset.csv\",\n",
    "    \"olist_order_items_dataset.csv\",\n",
    "    \"olist_products_dataset.csv\",\n",
    "    \"olist_customers_dataset.csv\",\n",
    "    \"olist_sellers_dataset.csv\",\n",
    "    \"olist_order_payments_dataset.csv\",\n",
    "    \"olist_order_reviews_dataset.csv\",\n",
    "    \"olist_geolocation_dataset.csv\",\n",
    "    \"product_category_name_translation.csv\",\n",
    "]\n",
    "\n",
    "print(\"Data files:\")\n",
    "all_present = True\n",
    "for f in expected_files:\n",
    "    path = data_path / f\n",
    "    if path.exists():\n",
    "        print(f\"  ✓ {f}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {f} - MISSING\")\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n✓ All 9 data files present\")\n",
    "else:\n",
    "    print(\"\\n✗ Some data files are missing. Please download from Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Quick Data Overview (only runs if files are present)\n",
    "if all_present:\n",
    "    print(\"Dataset Overview:\\n\")\n",
    "    total_memory = 0\n",
    "\n",
    "    for f in expected_files:\n",
    "        df = pd.read_csv(data_path / f)\n",
    "        mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "        total_memory += mem\n",
    "        print(f\"{f}\")\n",
    "        print(f\"  Rows: {df.shape[0]:,} | Cols: {df.shape[1]} | Memory: {mem:.2f} MB\\n\")\n",
    "\n",
    "    print(f\"Total memory: {total_memory:.2f} MB\")\n",
    "else:\n",
    "    print(\"Skipping data overview - files not present\")\n",
    "    total_memory = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Setup Summary\n",
    "print(\"=\" * 50)\n",
    "print(\"DAY 0 SETUP VALIDATION COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\"\"\n",
    "✓ Python environment: {sys.version.split()[0]}\n",
    "✓ GCP Project: {config['gcp']['project_id']}\n",
    "✓ GCS Bucket: {config['gcp']['bucket']}\n",
    "✓ Vertex AI Experiment: {config['vertex_ai']['experiment_name']}\n",
    "{'✓' if all_present else '✗'} Data files: {'All 9 CSVs present' if all_present else 'MISSING - download from Kaggle'}\n",
    "{'✓' if all_present else '○'} Total data size: {total_memory:.2f} MB\n",
    "\n",
    "{'Ready for Day 1: Data Engineering & EDA' if all_present else 'Please download data before proceeding'}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
