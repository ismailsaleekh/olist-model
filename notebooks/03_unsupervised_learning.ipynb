{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Unsupervised Learning (Clustering)\n",
    "\n",
    "**Day 2, Part 2: Customer Segmentation**\n",
    "\n",
    "## Objectives\n",
    "1. Prepare customer-level data for clustering\n",
    "2. Implement K-Means with optimal K selection\n",
    "3. Implement DBSCAN for density-based clustering\n",
    "4. Implement Hierarchical clustering with dendrogram\n",
    "5. Implement Gaussian Mixture Models\n",
    "6. Compare all clustering methods\n",
    "7. Profile clusters and assign business labels\n",
    "8. Add cluster assignments to datasets\n",
    "9. Save all artifacts\n",
    "\n",
    "## Key Principles\n",
    "- **Log transform** skewed features (monetary, frequency)\n",
    "- **StandardScaler** for normalization\n",
    "- **Business interpretability** - clusters should make business sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import clustering module\n",
    "from src.clustering import (\n",
    "    CLUSTERING_FEATURES,\n",
    "    prepare_clustering_data,\n",
    "    find_optimal_k,\n",
    "    perform_kmeans,\n",
    "    find_optimal_eps,\n",
    "    perform_dbscan,\n",
    "    compute_linkage_matrix,\n",
    "    perform_hierarchical,\n",
    "    find_optimal_gmm_components,\n",
    "    perform_gmm,\n",
    "    compare_clustering_methods,\n",
    "    profile_clusters,\n",
    "    assign_business_labels,\n",
    "    plot_elbow_silhouette,\n",
    "    plot_k_distance,\n",
    "    plot_dendrogram,\n",
    "    plot_gmm_bic_aic,\n",
    "    plot_clusters_pca,\n",
    "    plot_cluster_profiles_radar,\n",
    "    plot_cluster_distributions,\n",
    "    save_clustering_artifacts,\n",
    "    add_clusters_to_dataset,\n",
    ")\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 1: Load Customer Segments Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer-level data from Part 1\n",
    "customers = pd.read_parquet('../data/processed/customer_segments.parquet')\n",
    "\n",
    "print(f\"Customers: {len(customers):,}\")\n",
    "print(f\"Columns: {list(customers.columns)}\")\n",
    "print(f\"\\nSample:\")\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "print(\"Feature Statistics:\")\n",
    "numerical_cols = ['recency', 'frequency', 'monetary', 'avg_review_score', \n",
    "                  'avg_delivery_days', 'late_delivery_rate', 'avg_order_value']\n",
    "customers[numerical_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skewness - important for transformation decisions\n",
    "print(\"Feature Skewness (>1 suggests log transform):\")\n",
    "for col in numerical_cols:\n",
    "    skew = customers[col].skew()\n",
    "    print(f\"  {col}: {skew:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Clustering Data\n",
    "\n",
    "Key transformations:\n",
    "- Log transform highly skewed features (frequency, monetary)\n",
    "- StandardScaler for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "X_scaled, scaler, feature_names = prepare_clustering_data(customers)\n",
    "\n",
    "print(f\"\\nScaled data shape: {X_scaled.shape}\")\n",
    "print(f\"Feature names: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions before/after transformation\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Original distributions\n",
    "for idx, col in enumerate(['recency', 'frequency', 'monetary']):\n",
    "    ax = axes[0, idx]\n",
    "    customers[col].hist(bins=50, ax=ax, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{col} (Original)', fontsize=12)\n",
    "    ax.set_xlabel(col)\n",
    "\n",
    "# Log-transformed distributions\n",
    "axes[1, 0].set_title('recency (No transform needed)', fontsize=12)\n",
    "customers['recency'].hist(bins=50, ax=axes[1, 0], color='green', edgecolor='black', alpha=0.7)\n",
    "\n",
    "np.log1p(customers['frequency']).hist(bins=50, ax=axes[1, 1], color='green', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_title('frequency (Log transformed)', fontsize=12)\n",
    "\n",
    "np.log1p(customers['monetary']).hist(bins=50, ax=axes[1, 2], color='green', edgecolor='black', alpha=0.7)\n",
    "axes[1, 2].set_title('monetary (Log transformed)', fontsize=12)\n",
    "\n",
    "plt.suptitle('Feature Distributions: Original vs Transformed', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 3: K-Means Clustering\n",
    "\n",
    "Find optimal K using:\n",
    "- Elbow method (inertia)\n",
    "- Silhouette score (higher is better)\n",
    "- Davies-Bouldin index (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal K\n",
    "k_metrics = find_optimal_k(X_scaled, k_range=range(2, 9))\n",
    "k_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots directory\n",
    "Path('../models/plots').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Visualize K selection\n",
    "fig = plot_elbow_silhouette(k_metrics, save_path='../models/plots/kmeans_selection.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select optimal K based on silhouette\n",
    "best_k_idx = k_metrics['silhouette'].idxmax()\n",
    "optimal_k = k_metrics.loc[best_k_idx, 'k']\n",
    "print(f\"Optimal K based on silhouette: {optimal_k}\")\n",
    "print(f\"Silhouette score: {k_metrics.loc[best_k_idx, 'silhouette']:.3f}\")\n",
    "\n",
    "# For business interpretability, we might prefer K=4 for clear segmentation\n",
    "FINAL_K = 4\n",
    "print(f\"\\nFinal K chosen: {FINAL_K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means with final K\n",
    "kmeans, labels_kmeans = perform_kmeans(X_scaled, FINAL_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Means clusters in 2D (PCA)\n",
    "fig = plot_clusters_pca(X_scaled, labels_kmeans, title='K-Means Clusters (PCA)',\n",
    "                        save_path='../models/plots/kmeans_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Step 4: DBSCAN Clustering\n",
    "\n",
    "Density-based clustering - good for finding outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal eps using k-distance graph\n",
    "k_distances = find_optimal_eps(X_scaled, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot k-distance graph\n",
    "suggested_eps = np.percentile(k_distances, 95)\n",
    "fig = plot_k_distance(k_distances, suggested_eps=suggested_eps,\n",
    "                      save_path='../models/plots/dbscan_kdistance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DBSCAN\n",
    "eps = suggested_eps\n",
    "min_samples = max(10, len(X_scaled) // 1000)\n",
    "dbscan, labels_dbscan = perform_dbscan(X_scaled, eps, min_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN clusters\n",
    "fig = plot_clusters_pca(X_scaled, labels_dbscan, title='DBSCAN Clusters (PCA)',\n",
    "                        save_path='../models/plots/dbscan_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Step 5: Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute linkage matrix for dendrogram\n",
    "linkage_matrix, sample_idx = compute_linkage_matrix(X_scaled, sample_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dendrogram\n",
    "fig = plot_dendrogram(linkage_matrix, save_path='../models/plots/hierarchical_dendrogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hierarchical clustering\n",
    "hier, labels_hier = perform_hierarchical(X_scaled, FINAL_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Hierarchical clusters\n",
    "fig = plot_clusters_pca(X_scaled, labels_hier, title='Hierarchical Clusters (PCA)',\n",
    "                        save_path='../models/plots/hierarchical_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Step 6: Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of components\n",
    "gmm_metrics = find_optimal_gmm_components(X_scaled, n_range=range(2, 9))\n",
    "gmm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BIC/AIC\n",
    "fig = plot_gmm_bic_aic(gmm_metrics, save_path='../models/plots/gmm_bic_aic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GMM\n",
    "gmm, labels_gmm, gmm_proba = perform_gmm(X_scaled, FINAL_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GMM clusters\n",
    "fig = plot_clusters_pca(X_scaled, labels_gmm, title='GMM Clusters (PCA)',\n",
    "                        save_path='../models/plots/gmm_pca.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Step 7: Compare All Clustering Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "labels_dict = {\n",
    "    'K-Means': labels_kmeans,\n",
    "    'DBSCAN': labels_dbscan,\n",
    "    'Hierarchical': labels_hier,\n",
    "    'GMM': labels_gmm,\n",
    "}\n",
    "\n",
    "comparison = compare_clustering_methods(X_scaled, labels_dict)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Filter valid results\n",
    "valid_comparison = comparison[comparison['silhouette'].notna()]\n",
    "\n",
    "# Silhouette scores\n",
    "axes[0].bar(valid_comparison['name'], valid_comparison['silhouette'], color='steelblue', edgecolor='black')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Silhouette Score (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[0].axhline(y=0.3, color='r', linestyle='--', alpha=0.5, label='Good threshold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Davies-Bouldin\n",
    "axes[1].bar(valid_comparison['name'], valid_comparison['davies_bouldin'], color='coral', edgecolor='black')\n",
    "axes[1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1].set_title('Davies-Bouldin (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Calinski-Harabasz\n",
    "axes[2].bar(valid_comparison['name'], valid_comparison['calinski_harabasz'], color='green', edgecolor='black')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[2].set_title('Calinski-Harabasz (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/plots/clustering_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL SELECTION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nBased on metrics and business interpretability:\")\n",
    "print(\"- K-Means provides the best balance of performance and interpretability\")\n",
    "print(\"- Clear cluster boundaries for customer segmentation\")\n",
    "print(\"- Easy to deploy and explain to stakeholders\")\n",
    "print(f\"\\nFinal model: K-Means with K={FINAL_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Step 8: Cluster Profiling & Business Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to customer dataframe\n",
    "customers['cluster_id'] = labels_kmeans\n",
    "\n",
    "# Profile clusters\n",
    "profile_features = feature_names.copy()\n",
    "profiles, summary = profile_clusters(customers, 'cluster_id', profile_features)\n",
    "\n",
    "print(\"\\nCluster Summary:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign business labels based on profiles\n",
    "cluster_labels = assign_business_labels(summary)\n",
    "\n",
    "# Map labels to customers\n",
    "customers['customer_segment'] = customers['cluster_id'].map(cluster_labels)\n",
    "\n",
    "print(\"\\nFinal Segment Distribution:\")\n",
    "print(customers['customer_segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cluster profiles (radar chart)\n",
    "fig = plot_cluster_profiles_radar(summary, profile_features, cluster_labels,\n",
    "                                  save_path='../models/plots/cluster_radar.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions by cluster\n",
    "fig = plot_cluster_distributions(customers, 'cluster_id', profile_features, cluster_labels,\n",
    "                                 save_path='../models/plots/cluster_distributions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed cluster profiles\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLUSTER PROFILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for cluster_id in sorted(customers['cluster_id'].unique()):\n",
    "    segment = cluster_labels.get(cluster_id, f'Cluster {cluster_id}')\n",
    "    cluster_data = customers[customers['cluster_id'] == cluster_id]\n",
    "    \n",
    "    print(f\"\\n--- Cluster {cluster_id}: {segment.upper()} ---\")\n",
    "    print(f\"Size: {len(cluster_data):,} customers ({len(cluster_data)/len(customers)*100:.1f}%)\")\n",
    "    print(f\"Avg Recency: {cluster_data['recency'].mean():.0f} days\")\n",
    "    print(f\"Avg Frequency: {cluster_data['frequency'].mean():.2f} orders\")\n",
    "    print(f\"Avg Monetary: ${cluster_data['monetary'].mean():.2f}\")\n",
    "    print(f\"Avg Review Score: {cluster_data['avg_review_score'].mean():.2f}\")\n",
    "    print(f\"Late Delivery Rate: {cluster_data['late_delivery_rate'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "## Step 9: Add Cluster Labels to Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load featured datasets\n",
    "train_featured = pd.read_parquet('../data/processed/train_featured.parquet')\n",
    "val_featured = pd.read_parquet('../data/processed/val_featured.parquet')\n",
    "test_featured = pd.read_parquet('../data/processed/test_featured.parquet')\n",
    "\n",
    "print(f\"Train: {len(train_featured):,} rows\")\n",
    "print(f\"Val: {len(val_featured):,} rows\")\n",
    "print(f\"Test: {len(test_featured):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to all datasets\n",
    "train_featured = add_clusters_to_dataset(train_featured, customers)\n",
    "val_featured = add_clusters_to_dataset(val_featured, customers)\n",
    "test_featured = add_clusters_to_dataset(test_featured, customers)\n",
    "\n",
    "print(\"\\nTrain cluster distribution:\")\n",
    "print(train_featured['customer_segment'].value_counts())\n",
    "\n",
    "print(\"\\nVal cluster distribution:\")\n",
    "print(val_featured['customer_segment'].value_counts())\n",
    "\n",
    "print(\"\\nTest cluster distribution:\")\n",
    "print(test_featured['customer_segment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "## Step 10: Save All Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustering artifacts\n",
    "save_clustering_artifacts(\n",
    "    scaler=scaler,\n",
    "    model=kmeans,\n",
    "    profiles=profiles,\n",
    "    summary=summary,\n",
    "    cluster_labels=cluster_labels,\n",
    "    metrics=comparison,\n",
    "    feature_names=feature_names,\n",
    "    models_dir='../models',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated datasets\n",
    "train_featured.to_parquet('../data/processed/train_featured.parquet', index=False)\n",
    "val_featured.to_parquet('../data/processed/val_featured.parquet', index=False)\n",
    "test_featured.to_parquet('../data/processed/test_featured.parquet', index=False)\n",
    "\n",
    "print(\"\\n Saved train_featured.parquet\")\n",
    "print(\" Saved val_featured.parquet\")\n",
    "print(\" Saved test_featured.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated customer segments\n",
    "customers.to_parquet('../data/processed/customer_segments.parquet', index=False)\n",
    "print(\" Saved customer_segments.parquet with cluster labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved files\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SAVED FILES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Data files\n",
    "data_dir = Path(\"../data/processed\")\n",
    "for f in sorted(data_dir.glob(\"*.parquet\")):\n",
    "    size_mb = f.stat().st_size / 1024 / 1024\n",
    "    print(f\"  {f.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "# Model files\n",
    "models_dir = Path(\"../models\")\n",
    "for f in sorted(models_dir.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f\"  {f.name}: {size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-49",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Clustering Results\n",
    "\n",
    "| Model | Silhouette | Davies-Bouldin | Clusters |\n",
    "|-------|------------|----------------|----------|\n",
    "| K-Means | Best | Good | 4 |\n",
    "| Hierarchical | Good | Good | 4 |\n",
    "| GMM | Good | Good | 4 |\n",
    "| DBSCAN | Variable | Variable | Auto |\n",
    "\n",
    "**Selected Model**: K-Means (K=4)\n",
    "\n",
    "### Customer Segments\n",
    "\n",
    "| Segment | Description | Marketing Action |\n",
    "|---------|-------------|------------------|\n",
    "| Champions | High value, recent, satisfied | VIP treatment, loyalty rewards |\n",
    "| Potential Loyalists | Medium value, engaged | Nurture campaigns, upselling |\n",
    "| At-Risk | Not recent, declining engagement | Win-back campaigns |\n",
    "| Needs Attention | Recent but low satisfaction | Service improvement focus |\n",
    "\n",
    "### Artifacts Saved\n",
    "\n",
    "- `models/cluster_scaler.joblib` - StandardScaler\n",
    "- `models/clustering_model.joblib` - K-Means model\n",
    "- `models/cluster_profiles.csv` - Cluster statistics\n",
    "- `models/cluster_config.json` - Labels and config\n",
    "- `models/clustering_metrics.csv` - Comparison metrics\n",
    "- `data/processed/*_featured.parquet` - Updated with cluster_id, customer_segment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **Day 3: Supervised Learning** where we will:\n",
    "1. Use cluster_id as a feature for classification/regression\n",
    "2. Train models for customer satisfaction prediction\n",
    "3. Train models for delivery time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "cell-50",
   "metadata": {},
   "outputs": [],
   "source": "## Vertex AI Execution (Production)\n\nThe clustering pipeline was also executed on **Google Cloud Vertex AI** for production-grade training:\n\n### Vertex AI Job Details\n\n| Setting | Value |\n|---------|-------|\n| **Job ID** | `olist-clustering-1767162099` |\n| **Machine Type** | `n1-highmem-16` (16 vCPUs, 104GB RAM) |\n| **Container** | `sklearn-cpu.1-6:latest` |\n| **Status** | ✅ SUCCEEDED |\n\n### Production Clustering Results (67,344 customers)\n\n| Algorithm | Silhouette | Davies-Bouldin | Calinski-Harabasz |\n|-----------|------------|----------------|-------------------|\n| **K-Means** | 0.263 | 1.18 | 25,411 |\n| Hierarchical | 0.219 | 1.40 | 22,143 |\n| GMM | 0.208 | 1.45 | 22,351 |\n| DBSCAN | 0.148 | 1.40 | 7,905 |\n\n### Customer Segments (Final)\n\n| Cluster | Segment | Customers | % | Recency | Monetary | Review |\n|---------|---------|-----------|---|---------|----------|--------|\n| 0 | at_risk | 23,575 | 35% | 311 days | $190 | 4.22 |\n| 1 | potential_loyalists | 35,933 | 53% | 96 days | $198 | 4.16 |\n| 2 | needs_attention | 5,797 | 9% | 121 days | $204 | 2.43 |\n| 3 | champions | 2,039 | 3% | 158 days | $478 | 4.07 |\n\n### Artifacts Downloaded from GCS\n\n```\nmodels/\n├── clustering_model.joblib      # K-Means model (270KB)\n├── cluster_scaler.joblib        # StandardScaler\n├── cluster_profiles.csv         # Segment profiles\n├── cluster_config.json          # Labels & config\n├── clustering_metrics.csv       # Algorithm comparison\n├── kmeans_k_metrics.csv         # K selection metrics\n└── customer_segments_clustered.parquet  # Clustered data (4.1MB)\n```\n\n### Usage\n\n```python\nfrom src.gcp_utils import load_config, run_clustering_on_vertex_ai\n\nconfig = load_config()\njob = run_clustering_on_vertex_ai(config, optimal_k=4, sync=True)\n```"
  },
  {
   "cell_type": "code",
   "id": "bhmn12lpyi",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"DAY 2, PART 2: CLUSTERING COMPLETE!\")\nprint(\"=\" * 60)\nprint(f\"\"\"\nCompleted both local and Vertex AI clustering:\n- Compared 4 clustering algorithms\n- Selected K-Means with K=4\n- Created 4 customer segments\n- Ran production job on Vertex AI (n1-highmem-16)\n- Downloaded all artifacts from GCS\n\nReady for Day 3: Supervised Learning!\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}